library(rvest)
raw <- html_node(raw,.read-this-more-text)
raw <- html_node(raw,".read-this-more-text")%>%html_text()
library(rvest)
raw <- read_html("https://www.commonsensemedia.org/game-reviews/undertale/user-reviews/adult")
raw <- html_node(raw,".read-this-more-text")%>%html_text()
raw
raw <- html_node(raw,".read-this-more-text")
raw <- read_html("https://www.commonsensemedia.org/game-reviews/undertale/user-reviews/adult")
View(raw)
raw <- html_node(raw,".read-this-more-text")
raw <- read_html("https://www.commonsensemedia.org/game-reviews/undertale/user-reviews/adult")
rawp <- html_node(raw,".read-this-more-text")
rawp <- html_nodes(raw,".read-this-more-text")
View(rawp)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
raw <- read_html("http://www.319papago.idv.tw/lifeinfo/7-11/7-11-300-1.html")
raw1 <- html_nodes(raw, "h2+ table td:nth-child(1)") %>% html_text(raw)
raw2 <- html_nodes(raw, "h2+ table td:nth-child(2)") %>% html_text(raw)
raw3 <- html_nodes(raw, "h2+ table td:nth-child(3)") %>% html_text(raw)
raw4 <- html_nodes(raw, "h2+ table td:nth-child(4)") %>% html_text(raw)
need <- data.frame(raw1,raw2,raw3,raw4)
rawp <- html_nodes(raw,".views-field:nth-child(2) div")
rawp <- html_nodes(raw," .views-field:nth-child(2) div")
View(raw)
raw <- read_html("http://www.319papago.idv.tw/lifeinfo/7-11/7-11-300-1.html")
View(raw)
raw <- read_html("https://www.commonsensemedia.org/game-reviews/undertale/user-reviews/adult")
rawp <-html_nodes(raw,".views-field:nth-child(2) div")
View(rawp)
View(rawp)
rawp <-html_nodes(raw," .views-field:nth-child(2) div ")
rawp <-html_nodes(raw," .views-field:nth-child(2) div ")%>%html_text(raw)
View(raw)
rawp
rawp <-html_nodes(raw," .views-field:nth-child(2) div ")
rawp
rawp <-html_nodes(raw," .read-this-more-text")
rawp
rawp <-html_nodes(raw," #read-this-more-text")
rawp
rawp <-html_nodes(raw," read-this-more-text")
rawp
rawp <-html_nodes(raw," .read-this-more-text")
rawp
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale")
rawp <-html_nodes(raw," .review-body")
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale")
View(raw)
rawp <-html_nodes(raw," .review-body")
rawp <-html_nodes(raw," .review_body")
rawp
rawp <-html_nodes(raw," .review_body")%>%html_text(raw)
rawp
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/critic-reviews")
rawp <-html_nodes(raw," .review_body")%>%html_text(raw)
rawp
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/user-reviews")
rawPSU <-html_nodes(raw," .review_body")%>%html_text(raw)
rawPSU
library(rvest)
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/critic-reviews")
rawPSC <-html_nodes(raw," .review_body")%>%html_text(raw)
rawPSC
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/user-reviews")
rawPSU <-html_nodes(raw," .review_body")%>%html_text(raw)
rawPSU
raw <- read_html("https://www.metacritic.com/game/switch/undertale/critic-reviews")
rawNSC <-html_nodes(raw," .review_body")%>%html_text(raw)
rawNSC
raw <- read_html("https://www.metacritic.com/game/switch/undertale/user-reviews")
rawNSU <-html_nodes(raw," .review_body")%>%html_text(raw)
rawNSU
knitr::opts_chunk$set(echo = TRUE)
library(NLP)
library(tm)
library(stats)
library(proxy)
library(dplyr)
library(readtext)
library(jiebaRD)
library(jiebaR)
library(slam)
library(Matrix)
library(tidytext)
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/critic-reviews")
library(rvest)
library(NLP)
library(tm)
library(stats)
library(proxy)
library(dplyr)
library(readtext)
library(jiebaRD)
library(jiebaR)
library(slam)
library(Matrix)
library(tidytext)
library(rvest)
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/critic-reviews")
rawPSC <-html_nodes(raw," .review_body")%>%html_text(raw)
raw <- read_html("https://www.metacritic.com/game/playstation-4/undertale/user-reviews")
rawPSU <-html_nodes(raw," .review_body")%>%html_text(raw)
raw <- read_html("https://www.metacritic.com/game/switch/undertale/critic-reviews")
rawNSC <-html_nodes(raw," .review_body")%>%html_text(raw)
raw <- read_html("https://www.metacritic.com/game/switch/undertale/user-reviews")
rawNSU <-html_nodes(raw," .review_body")%>%html_text(raw)
raw <- read_html("https://www.metacritic.com/game/pc/undertale/critic-reviews")
rawPCC <-html_nodes(raw," .review_body")%>%html_text(raw)
raw <- read_html("https://www.metacritic.com/game/pc/undertale/user-reviews")
rawPCU <-html_nodes(raw," .review_body")%>%html_text(raw)
list.rating <- list(rawPSC,rawPSU,rawNSC,rawNSU,rawPCC,rawPCU)
titles <- c("PS4.critic","PS4.user","NS.critic","NS.user","PC.critic","PC.user")
docs = Corpus(VectorSource(list.rating))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
})
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords,stopwords::stopwords(language = "en",source = "snowball"))
docsPTD <- tm_map(docs, PlainTextDocument)
keywords <- read.csv("keywords.csv")
str(docs)
keywords = read.csv("keywords.csv")
mixseg = worker()
keys = as.matrix(keywords)
new_user_word(mixseg, keys)
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
d.corpus <- Corpus(VectorSource(seg))
tdm <- TermDocumentMatrix(d.corpus)
tf <- as.matrix(tdm)
DF <- tidy(tf)
DF
# tf-idf computation
N = tdm$ncol
tf <- apply(tdm, 2, sum)
idfCal <- function(word_doc)
{
log2( N / nnzero(word_doc) )
}
idf <- apply(tdm, 1, idfCal)
doc.tfidf <- as.matrix(tdm)
for(x in 1:nrow(tdm))
{
for(y in 1:ncol(tdm))
{
doc.tfidf[x,y] <- (doc.tfidf[x,y] / tf[y]) * idf[x]
}
}
findZeroId = as.matrix(apply(doc.tfidf, 1, sum))
tfidfnn = doc.tfidf[-which(findZeroId == 0),]
write.csv(tfidfnn, "show.csv")
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
})
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords,stopwords::stopwords(language = "en",source = "snowball"))
docsPTD <- tm_map(docs, PlainTextDocument)
keywords <- read.csv("keywords.csv")
str(docs)
keywords = read.csv("keywords.csv")
mixseg = worker()
keys = as.matrix(keywords)
new_user_word(mixseg, keys)
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(docs, jieba_tokenizer)
write.csv(dics, "doc.csv")
setwd("C:/Users/perot/Desktop/NTU-CSX4001/Week_6/hw_6/Project_1")
write.csv(docs, "doc.csv")
tfidfnn = as.factor(doc.tfidf[-which(findZeroId == 0),])
write.csv(tfidfnn, "show.csv")
tfidfnn = doc.tfidf[-which(findZeroId == 0),]
write.csv(tfidfnn, "show.csv")
list.rating
write.csv(list.rating,"list.csv")
write.csv(list.rating,"list.txt")
write.csv(list.rating,"list.csv",check.rows = F)
write.csv(list.rating,"list.csv",check.rows = TRUE)
write.csv(list.rating,"list.csv")
list.rating

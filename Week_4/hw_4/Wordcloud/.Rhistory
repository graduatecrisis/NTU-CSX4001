read.csv(address.csv)
read.csv(address.csv)
map <- leaflet() %>% addTiles() %>% setView(120.9689,24.7966, zoom = 13)
library(leaflet)
read.csv(address.csv)
address.csv
setwd("C:/Users/perot/Desktop/NTU-CSX4001/Week_4/hw_4/map")
address.csv
read.csv("address")
read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
data <- read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
View(data)
data[1][2]
data <- data.frame(data)
View(data)
data[1][2]
data[1]
data[2]
data.1[2]
data$緯度[2]
add.dot(data$緯度[i],data$經度[i])
add.dot<-function(x,y){
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=y, lat=x)
m
}
library(leaflet)
data <- read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
data <- data.frame(data)
map <- leaflet() %>% addTiles() %>% setView(120.9689,24.7966, zoom = 13)
data$緯度[2]
for i in c(1:135){
add.dot(data$緯度[i],data$經度[i])
}
for (i in c(1:135)){
add.dot(data$緯度[i],data$經度[i])
}
mao
map
add.dot<-function(x,y){
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=y, lat=x)
return m
}
library(leaflet)
data <- read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
data <- data.frame(data)
map <- leaflet() %>% addTiles() %>% setView(120.9689,24.7966, zoom = 13)
data$緯度[2]
for (i in c(1:135)){
map<- add.dot(data$緯度[i],data$經度[i])
}
map
leaflet(data = data[1:20,]) %>% addTiles() %>%
addMarkers(~long, ~lat, popup = ~as.character(mag), label = ~as.character(mag))
leaflet(data = data[1:20,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度, popup = ~as.character(mag), label = ~as.character(mag))
leaflet(data = data[1:20,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
leaflet(data = data[1:135]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
leaflet(data = data[1:135]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
View(data)
leaflet(data = data[1:20]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
leaflet(data = data[20:2]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
leaflet(data = data[1:135,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
leaflet(data = data[1:135,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
library(leaflet)
data <- read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
data <- data.frame(data)
leaflet(data = data[1:135,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
library(leaflet)
data <- read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
leaflet(data = data[1:135,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
## 載入資料庫
```{r setup}
library(leaflet)
data <- read.csv("C:\\Users\\perot\\Desktop\\NTU-CSX4001\\Week_4\\hw_4\\map\\address.csv")
leaflet(data = data[1:135,]) %>% addTiles() %>%
addMarkers(~經度, ~緯度)
setwd("C:/Users/perot/Desktop/NTU-CSX4001/Week_4/hw_4/Textcloud")
install.packages("jiebaR")
install.packages("rtweet")
install.packages("tidytext")
install.packages("dplyr")
install.packages("stringr")
require(devtools)
library(tidytext)
library(dplyr)
install.packages("tidytext")
library(tidytext)
library(dplyr)
library(stringr)
library(rtweet)
library(wordcloud2)
create_token(
app = "CSX4001",
consumer_key = "os9BSEDDSzZKaa79hWbXeAUmm",
consumer_secret = "K6KcZy4ZhQYpFoMWKKgZjVTXKSP4gAvTc760meWwmlQLJEWsAg",
access_token = "3301954536-dvRxov51hUw3tU8yrJJnIDGHfhL0gVimjGX92u6",
access_secret = "4Y7uewr8SyVmdAXuFBp2jXKskaLVuasmtPoizyR2Fx2x5",
)
#Grab tweets - note: reduce to 1000 if it's slow
hmt <- search_tweets(
"#undertale", n = 2000, include_rts = FALSE
)
hmt$text
#Unnest the words - code via Tidy Text
hmtTable <- hmt %>%
unnest_tokens(word, text)
View(hmtTable)
#remove stop words - aka typically very common words such as "the", "of" etc
data(stop_words)
hmtTable <- hmtTable %>%
anti_join(stop_words)
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ'))
#do a word count
hmtTable <- hmtTable %>%
count(word, sort = TRUE)
hmtTable
wordcloud2(hmtTable, size=0.7)
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり'))
wordcloud2(hmtTable, size=0.7)
hmtTable
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり','さん','ない','か','です',
'だ'))
wordcloud2(hmtTable, size=0.7)
hmtTable
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり','さん','ない','か','です',
'だ','2','も','れ'))
wordcloud2(hmtTable, size=0.7)
hmtTable
View(hmtTable)
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり','さん','ない','か','です',
'だ','2','も','れ','描','<U+307E>','<U+307E><U+3059>','<U+307F>','3','<U+304B><U+3089>'))
wordcloud2(hmtTable, size=1)
hmtTable
wordcloud2(hmtTable, size=1,min.freq = 7)
wordcloud(words = d$word, freq = d$n, min.freq = 10,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
install.packages("tm")  # for text mining
install.packages("wordcloud") # word-cloud generator
install.packages("RColorBrewer") # color palettes
# Load
library("wordcloud")
library("RColorBrewer")
wordcloud(words = d$word, freq = d$n, min.freq = 10,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 10,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 10,
random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 21,
random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 21,
random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 21,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり','さん','ない','か','です',
'だ','2','も','れ','描','<U+307E>','<U+307E><U+3059>','<U+307F>','3','<U+304B><U+3089>',"ます",'や','もう','ちゃん',
'かな','けど','しま',))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 21,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり','さん','ない','か','です',
'だ','2','も','れ','描','<U+307E>','<U+307E><U+3059>','<U+307F>','3','<U+304B><U+3089>',"ます",'や','もう','ちゃん',
'かな','けど','しま'))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 21,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
#Remove other nonsense words
hmtTable <-hmtTable %>%
filter(!word %in% c('t.co', 'https', 'undertale', "art", "it's", 'el', 'en', 'tv','に','た','が','て','の','と','は',
'で','を','って','い','な','っ','し','した','たい','アンダー','テール','繋がり','さん','ない','か','です',
'だ','2','も','れ','描','<U+307E>','<U+307E><U+3059>','<U+307F>','3','<U+304B><U+3089>',"ます",'や','もう','ちゃん',
'かな','けど','しま','ま','よ'))
wordcloud(words = hmtTable$word, freq = hmtTable$n, min.freq = 21,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
